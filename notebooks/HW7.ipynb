{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expression Evaluation\n",
    " \n",
    "***Student Name:*** put your name here\n",
    "    \n",
    "    \n",
    "## Submission\n",
    "\n",
    "After answering all the questions, save your work in **PDF** format file (if saving in PDF format is not working submit Notebook-formated `.ipynb` version).\n",
    "    \n",
    "- Double-click on this cell\n",
    "- Enter your name in the above placeholder, and evaluate this cell to render it correctly\n",
    "- Save your work by pressing <span class=\"fa-save fa\"/> button in the toolbar\n",
    "- Go to menu \"File\" -> \"Download as\"\n",
    "- Select \"PDF via Latex (.pdf)\"\n",
    "- Use downloaded file for Blackboard submission \n",
    "\n",
    "For more information, see https://www.codecademy.com/articles/how-to-use-jupyter-notebooks\n",
    "\n",
    "### Coding Style\n",
    "\n",
    "- Use functional F# style for writing your programs.\n",
    "- Make sure that you do not use mutable variables & loops.\n",
    "- Any imperative style programming is prohibited unless specified in the problem description.\n",
    "\n",
    "For additional information of F# coding style see [F# Style Guide](https://docs.microsoft.com/en-us/dotnet/fsharp/style-guide/).\n",
    "\n",
    "### Before You Submit\n",
    "\n",
    "You are required to test that your submission works properly before submission. Make sure that your program compiles without errors. Once you have verified that the submission is correct, you can submit your work.\n",
    "\n",
    "### Your Submission\n",
    "\n",
    "Program submissions should be done through the Blackboard.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "\n",
    "In this assignment, you will write a lexical analyzer and an interpreter for string expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Write a lexical analyzer which uses above types to generate sequence of tokens from the input string. You will tokenize strings composed of integer numbers and arithmetic operations. Let's define these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//\n",
    "// RUN THIS CELL BEFORE CONTINUE\n",
    "//\n",
    "type TOKEN =\n",
    "    | INT of int // integer number\n",
    "    | ADD_OP   // addition operation\n",
    "    | SUB_OP   // subtraction operation\n",
    "    | MUL_OP   // multiplication operation\n",
    "    | UNKNOWN  // uknown symbol\n",
    "    | EOF      // end of input\n",
    "    \n",
    "// helper functions\n",
    "let charsToInt (cs:char list) :int =\n",
    "    List.fold (fun a c -> a + string c) \"\" cs |> int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lexical analyzer is a finite automaton (finite state machine) that takes a string and produces a sequence of tokens corresponding to proper language elements in the string.\n",
    "\n",
    "![](lexer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition between the states can be defined as a collection of recursive functions. Each function represents a series of transitions that happen in the state of a finite automaton. For example:\n",
    "\n",
    "- In `START` state, it's possible to go to `OP` state if an arithmetic operation character is received, or go to `NUMBER` state if the input starts with a number\n",
    "- In `OP` state, it's *only* possible to go to `SPACE` state if the input starts from the space character.\n",
    "\n",
    "\n",
    "When finite automaton leaves a particular state, the appropriate token is generated. That corresponds to the same action in the recursive function. Leaving the state is associated with a function termination, and so a function returns a *list of tokens* which where accumulated through the recursive calls attaching the latest generated token to the beginning of the list.\n",
    "\n",
    "If finite automaton receives a character that does not correspond to the appropriate transition then the function must return the `UNKNOWN` token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexer (20 pts)\n",
    "\n",
    "**RUN ABOVE CELLS BEFORE CONTINUE**\n",
    "\n",
    "First, write some helper function that will help to write the lexical analyzer. A function that identifies if a character is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This function classifies whether a character is a number or not.\n",
    "let isNumber (c:char) :bool =\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, a function that identifies if a character is an arithmetic operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This function classifies whether a character is an arithmetic operation or not.\n",
    "let isOperation (c:char) :bool =\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are already `start` and `number` functions defined as an examples of the state transitions. Write the rest of the functions in a similar manner to complete the automaton program.\n",
    "\n",
    "*Note: Because all functions are recursive and they call each other, the F# provides special syntax for such [mutually recursive function](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/functions/recursive-functions-the-rec-keyword#mutually-recursive-functions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let rec start (input:char list) =    \n",
    "    match input with\n",
    "    | c::str when isNumber c    -> (number [c] str)\n",
    "//    | c::str when isOperation c -> (operation c str)\n",
    "    | []                        -> [EOF]\n",
    "    | _                         -> [UNKNOWN]\n",
    "    \n",
    "and number (nums:char list) (input:char list) =\n",
    "    let makeIntLit cs = cs |> List.rev |> charsToInt |> INT\n",
    "    match input with\n",
    "    | []       -> (makeIntLit nums)::[EOF]      \n",
    "//    | ' '::str -> (makeIntLit nums)::(space str)    \n",
    "    | c::str when isNumber c -> (number (c::nums) str)\n",
    "    | _        -> [UNKNOWN]\n",
    "       \n",
    "//and space (input:char list) =\n",
    "//    ...\n",
    "    \n",
    "//and operation (c:char) input =\n",
    "//    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lexer` function take an input string with calls the above finite automaton functions. The result of this function is a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let lexer (input:string) :TOKEN list =\n",
    "    input |> Seq.toList |> start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexer \"123\" |> printfn \"%A\" // [INT 123; EOF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexer \"10 + 20 - 2 * 10\" |> printfn \"%A\" // [INT 10; ADD_OP; INT 20; SUB_OP; INT 2; MUL_OP; INT 10; EOF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexer \"10 + 20 - a\" |> printfn \"%A\" // [INT 10; ADD_OP; INT 20; SUB_OP; UNKNOWN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression Evaluation (10 pts)\n",
    "\n",
    "There are three different ways how the expressions can be represented:\n",
    "\n",
    "- **Prefix expression** has the form `<op> <a> <b>` where an operator `op` is preceded the every pair of operands `a` and `b`.\n",
    "- **Infix expression**  has the form `<a> <op> <b>` where an operator `op` is in-between every pair of operands `a` and `b`.\n",
    "- **Postfix expression** has the form `<a> <b> <op>` where an operator `op` is followed for every pair of operands `a` and `b`.\n",
    "\n",
    "\n",
    "You will write an `infix` function that evaluates sequence of tokens in infix form using the input from the lexical analyzer, and output integer result value. All binary operations have the same precedence, and they are evaluated from left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let rec infix (tkns:TOKEN list) :int =\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"10 * 20 + 30 - 40\" |> lexer |> infix // 190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Bonus (15 pts)\n",
    "\n",
    "Write a `postfix` function which evaluates sequence of tokens in postfix notation form using the input from the lexical analyzer, and output integer result value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let postfix (tkns:TOKEN list) :int =\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"10 5 20 10 + - *\" |> lexer |> postfix // -250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"10 20 + 5 - 10 *\" |> lexer |> postfix // -250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"1 3 + 5 2 - *\" |> lexer |> postfix // 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (F#)",
   "language": "F#",
   "name": ".net-fsharp"
  },
  "language_info": {
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "C#",
   "pygments_lexer": "fsharp",
   "version": "4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
